{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MLSA Transformer Project: Python Code Summarization (FINAL STABLE)\n",
                "\n",
                "This version is **100% synchronized** with your local `src/model.py`. Any weights saved here will work on your Mac without errors.\n",
                "\n",
                "## 1. Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install -q torch datasets transformers torchmetrics tqdm\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "!mkdir -p \"/content/drive/My Drive/MLSA_Transformer_Checkpoints\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from datasets import load_dataset\n",
                "from transformers import RobertaTokenizer\n",
                "import numpy as np\n",
                "import copy\n",
                "import math\n",
                "import os\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "SAVE_DIR = \"/content/drive/My Drive/MLSA_Transformer_Checkpoints\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Dataset Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CodeSummarizationDataset(Dataset):\n",
                "    def __init__(self, split, tokenizer, max_code_len=256, max_summary_len=128, subset_size=None):\n",
                "        self.dataset = load_dataset(\"code_x_glue_ct_code_to_text\", \"python\", split=split)\n",
                "        if subset_size and subset_size < len(self.dataset):\n",
                "            self.dataset = self.dataset.select(range(subset_size))\n",
                "        self.tokenizer = tokenizer\n",
                "        self.max_code_len = max_code_len\n",
                "        self.max_summary_len = max_summary_len\n",
                "\n",
                "    def __len__(self): return len(self.dataset)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        item = self.dataset[idx]\n",
                "        c_enc = self.tokenizer(item['code'], max_length=self.max_code_len, padding='max_length', truncation=True, return_tensors='pt')\n",
                "        s_enc = self.tokenizer(item['docstring'], max_length=self.max_summary_len, padding='max_length', truncation=True, return_tensors='pt')\n",
                "        \n",
                "        labels = s_enc['input_ids'].squeeze(0)\n",
                "        return {\n",
                "            'input_ids': c_enc['input_ids'].squeeze(0), \n",
                "            'decoder_input_ids': labels.clone(), \n",
                "            'labels': labels\n",
                "        }\n",
                "\n",
                "def get_dataloaders(batch_size=64):\n",
                "    tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
                "    train_ds = CodeSummarizationDataset('train', tokenizer, subset_size=50000)\n",
                "    val_ds = CodeSummarizationDataset('validation', tokenizer, subset_size=5000)\n",
                "    print(f\"Training samples: {len(train_ds)}, Validation: {len(val_ds)}\")\n",
                "    return DataLoader(train_ds, batch_size=batch_size, shuffle=True), DataLoader(val_ds, batch_size=batch_size), tokenizer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Transformer Architecture (Match to `src/model.py`)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class PositionalEncoding(nn.Module):\n",
                "    def __init__(self, max_len, d_model):\n",
                "        super(PositionalEncoding, self).__init__()\n",
                "        self.d_model = d_model\n",
                "        pe = torch.zeros(max_len, d_model)\n",
                "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
                "        slope = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
                "        pe[:, 0::2] = torch.sin(position * slope)\n",
                "        pe[:, 1::2] = torch.cos(position * slope)\n",
                "        self.register_buffer('pe', pe.unsqueeze(0))\n",
                "    def forward(self, x):\n",
                "        return (x * np.sqrt(self.d_model)) + self.pe[:, :x.size(1), :]\n",
                "\n",
                "class MultiHeadedAttention(nn.Module):\n",
                "    def __init__(self, n_heads, d_model, dropout=0.1):\n",
                "        super(MultiHeadedAttention, self).__init__()\n",
                "        self.n_heads, self.d_model, self.d_k = n_heads, d_model, d_model // n_heads\n",
                "        self.linear_query = nn.Linear(d_model, d_model)\n",
                "        self.linear_key = nn.Linear(d_model, d_model)\n",
                "        self.linear_value = nn.Linear(d_model, d_model)\n",
                "        self.linear_out = nn.Linear(d_model, d_model)\n",
                "        self.dropout = nn.Dropout(p=dropout)\n",
                "    def make_chunks(self, x):\n",
                "        return x.view(x.size(0), x.size(1), self.n_heads, self.d_k).transpose(1, 2)\n",
                "    def init_keys(self, key):\n",
                "        self.proj_key = self.make_chunks(self.linear_key(key))\n",
                "        self.proj_value = self.make_chunks(self.linear_value(key))\n",
                "    def forward(self, query, mask=None):\n",
                "        if mask is not None and mask.dim() == 3: mask = mask.unsqueeze(1)\n",
                "        q = self.make_chunks(self.linear_query(query))\n",
                "        scores = torch.matmul(q, self.proj_key.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
                "        if mask is not None: scores = scores.masked_fill(mask == 0, -1e9)\n",
                "        alphas = self.dropout(F.softmax(scores, dim=-1))\n",
                "        context = torch.matmul(alphas, self.proj_value).transpose(1, 2).contiguous().view(query.size(0), -1, self.d_model)\n",
                "        return self.linear_out(context)\n",
                "\n",
                "class SubLayerWrapper(nn.Module):\n",
                "    def __init__(self, d_model, dropout):\n",
                "        super().__init__()\n",
                "        self.norm, self.drop = nn.LayerNorm(d_model), nn.Dropout(dropout)\n",
                "    def forward(self, x, sublayer, is_self_attn=False, **kwargs):\n",
                "        norm_x = self.norm(x)\n",
                "        if is_self_attn: sublayer.init_keys(norm_x)\n",
                "        return x + self.drop(sublayer(norm_x, **kwargs))\n",
                "\n",
                "class EncoderLayer(nn.Module):\n",
                "    def __init__(self, n_heads, d_model, ff_units, dropout=0.1):\n",
                "        super().__init__()\n",
                "        self.n_heads, self.d_model = n_heads, d_model\n",
                "        self.self_attn_heads = MultiHeadedAttention(n_heads, d_model, dropout=dropout)\n",
                "        self.ffn = nn.Sequential(nn.Linear(d_model, ff_units), nn.ReLU(), nn.Dropout(dropout), nn.Linear(ff_units, d_model))\n",
                "        self.sublayers = nn.ModuleList([SubLayerWrapper(d_model, dropout) for _ in range(2)])\n",
                "    def forward(self, query, mask=None):\n",
                "        att = self.sublayers[0](query, sublayer=self.self_attn_heads, is_self_attn=True, mask=mask)\n",
                "        return self.sublayers[1](att, sublayer=self.ffn)\n",
                "\n",
                "class DecoderLayer(nn.Module):\n",
                "    def __init__(self, n_heads, d_model, ff_units, dropout=0.1):\n",
                "        super().__init__()\n",
                "        self.n_heads, self.d_model = n_heads, d_model\n",
                "        self.self_attn_heads = MultiHeadedAttention(n_heads, d_model, dropout=dropout)\n",
                "        self.cross_attn_heads = MultiHeadedAttention(n_heads, d_model, dropout=dropout)\n",
                "        self.ffn = nn.Sequential(nn.Linear(d_model, ff_units), nn.ReLU(), nn.Dropout(dropout), nn.Linear(ff_units, d_model))\n",
                "        self.sublayers = nn.ModuleList([SubLayerWrapper(d_model, dropout) for _ in range(3)])\n",
                "    def init_keys(self, states): self.cross_attn_heads.init_keys(states)\n",
                "    def forward(self, query, source_mask=None, target_mask=None):\n",
                "        att1 = self.sublayers[0](query, sublayer=self.self_attn_heads, is_self_attn=True, mask=target_mask)\n",
                "        att2 = self.sublayers[1](att1, sublayer=self.cross_attn_heads, mask=source_mask)\n",
                "        return self.sublayers[2](att2, sublayer=self.ffn)\n",
                "\n",
                "class EncoderTransf(nn.Module):\n",
                "    def __init__(self, encoder_layer, n_layers=1, max_len=512):\n",
                "        super().__init__()\n",
                "        self.d_model = encoder_layer.d_model\n",
                "        self.pe = PositionalEncoding(max_len, self.d_model)\n",
                "        self.norm = nn.LayerNorm(self.d_model)\n",
                "        self.layers = nn.ModuleList([copy.deepcopy(encoder_layer) for _ in range(n_layers)])\n",
                "    def forward(self, query, mask=None):\n",
                "        x = self.pe(query)\n",
                "        for layer in self.layers: x = layer(x, mask)\n",
                "        return self.norm(x)\n",
                "\n",
                "class DecoderTransf(nn.Module):\n",
                "    def __init__(self, decoder_layer, n_layers=1, max_len=512):\n",
                "        super(DecoderTransf, self).__init__()\n",
                "        self.d_model = decoder_layer.d_model\n",
                "        self.pe = PositionalEncoding(max_len, self.d_model)\n",
                "        self.norm = nn.LayerNorm(self.d_model)\n",
                "        self.layers = nn.ModuleList([copy.deepcopy(decoder_layer) for _ in range(n_layers)])\n",
                "    def init_keys(self, states): \n",
                "        for layer in self.layers: layer.init_keys(states)\n",
                "    def forward(self, query, s_mask=None, t_mask=None):\n",
                "        x = self.pe(query)\n",
                "        for layer in self.layers: x = layer(x, s_mask, t_mask)\n",
                "        return self.norm(x)\n",
                "\n",
                "class EncoderDecoderTransf(nn.Module):\n",
                "    def __init__(self, encoder, decoder, src_vocab_size, tgt_vocab_size, max_len=512):\n",
                "        super(EncoderDecoderTransf, self).__init__()\n",
                "        self.encoder, self.decoder, self.d_model = encoder, decoder, encoder.d_model\n",
                "        self.src_embed = nn.Embedding(src_vocab_size, self.d_model)\n",
                "        self.tgt_embed = nn.Embedding(tgt_vocab_size, self.d_model)\n",
                "        self.out_linear = nn.Linear(self.d_model, tgt_vocab_size)\n",
                "        self.register_buffer('subsequent_mask', (1 - torch.triu(torch.ones((1, max_len, max_len)), diagonal=1)))\n",
                "    def encode(self, src, mask=None):\n",
                "        states = self.encoder(self.src_embed(src), mask)\n",
                "        self.decoder.init_keys(states); return states\n",
                "    def decode(self, tgt, s_mask=None, t_mask=None):\n",
                "        if t_mask is None: t_mask = self.subsequent_mask[:, :tgt.size(1), :tgt.size(1)]\n",
                "        outputs = self.decoder(self.tgt_embed(tgt), s_mask, t_mask)\n",
                "        return self.out_linear(outputs)\n",
                "    def forward(self, src, tgt):\n",
                "        self.encode(src)\n",
                "        return self.decode(tgt)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Faster Training Loop (RECOVERY ENABLED)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train(resume_epoch=None):\n",
                "    batch_size, epochs, lr = 64, 10, 1e-4\n",
                "    d_model, n_heads, n_layers, ff_units = 256, 8, 4, 512\n",
                "    train_loader, val_loader, tokenizer = get_dataloaders(batch_size=batch_size)\n",
                "    \n",
                "    enclayer = EncoderLayer(n_heads, d_model, ff_units)\n",
                "    declayer = DecoderLayer(n_heads, d_model, ff_units)\n",
                "    encoder = EncoderTransf(enclayer, n_layers, max_len=256)\n",
                "    decoder = DecoderTransf(declayer, n_layers, max_len=128)\n",
                "    model = EncoderDecoderTransf(encoder, decoder, tokenizer.vocab_size, tokenizer.vocab_size, max_len=128).to(device)\n",
                "    \n",
                "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
                "    criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
                "    \n",
                "    start_epoch = 0\n",
                "    if resume_epoch:\n",
                "        ckpt = os.path.join(SAVE_DIR, f'checkpoint_epoch_{resume_epoch}.pt')\n",
                "        if os.path.exists(ckpt):\n",
                "            model.load_state_dict(torch.load(ckpt))\n",
                "            start_epoch = resume_epoch\n",
                "            print(f\"--- Resumed from Epoch {resume_epoch} ---\")\n",
                "\n",
                "    for epoch in range(start_epoch, epochs):\n",
                "        model.train(); total_loss = 0\n",
                "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
                "        for batch in pbar:\n",
                "            ids, labels = batch['input_ids'].to(device), batch['labels'].to(device)\n",
                "            optimizer.zero_grad()\n",
                "            logits = model(ids, labels[:, :-1])\n",
                "            loss = criterion(logits.view(-1, tokenizer.vocab_size), labels[:, 1:].contiguous().view(-1))\n",
                "            loss.backward(); optimizer.step()\n",
                "            total_loss += loss.item()\n",
                "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
                "        \n",
                "        path = os.path.join(SAVE_DIR, f'checkpoint_epoch_{epoch+1}.pt')\n",
                "        torch.save(model.state_dict(), path)\n",
                "        print(f\"Epoch {epoch+1} finished and saved to Google Drive.\")\n",
                "\n",
                "train()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}